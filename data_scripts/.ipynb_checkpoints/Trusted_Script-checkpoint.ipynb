{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c8536f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# If the file is in CSV format, you can simply use \"pd.read_csv\"\n",
    "\n",
    "# Importing the training datasets\n",
    "dt_2007 = pd.read_excel('../data/raw/datatran2007.xlsx')\n",
    "dt_2008 = pd.read_excel('../data/raw/datatran2008.xlsx')\n",
    "dt_2009 = pd.read_excel('../data/raw/datatran2009.xlsx')\n",
    "dt_2010 = pd.read_excel('../data/raw/datatran2010.xlsx')\n",
    "dt_2011 = pd.read_excel('../data/raw/datatran2011.xlsx')\n",
    "dt_2012 = pd.read_excel('../data/raw/datatran2012.xlsx')\n",
    "dt_2013 = pd.read_excel('../data/raw/datatran2013.xlsx')\n",
    "dt_2014 = pd.read_excel('../data/raw/datatran2014.xlsx')\n",
    "dt_2015 = pd.read_excel('../data/raw/datatran2015.xlsx')\n",
    "dt_2016 = pd.read_excel('../data/raw/datatran2016.xlsx')\n",
    "dt_2017 = pd.read_excel('../data/raw/datatran2017.xlsx')\n",
    "dt_2018 = pd.read_excel('../data/raw/datatran2018.xlsx')\n",
    "dt_2019 = pd.read_excel('../data/raw/datatran2019.xlsx')\n",
    "dt_2020 = pd.read_excel('../data/raw/datatran2020.xlsx')\n",
    "\n",
    "# Concatenating the training datasets\n",
    "df_training = pd.concat([dt_2007, dt_2008, dt_2009, dt_2010, dt_2011, dt_2012, dt_2013, dt_2014, dt_2015, dt_2016, dt_2017, dt_2018, dt_2019, dt_2020], ignore_index = True)\n",
    "\n",
    "# Importing the test dataset\n",
    "df_test = pd.read_excel('../data/raw/datatran2021.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f57e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69c4922",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5904167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As there were unique variables in certain years, this ended up...\n",
    "# causing a conflict when cleaning these databases together...\n",
    "# Therefore, only the variables to be used in model training were retained\n",
    "\n",
    "# Common drops from 2007 to 2020\n",
    "df_training.drop('id', axis = 1, inplace = True)\n",
    "df_training.drop('data_inversa', axis = 1, inplace = True)\n",
    "df_training.drop('horario', axis = 1, inplace = True)\n",
    "df_training.drop('municipio', axis = 1, inplace = True)\n",
    "df_training.drop('uso_solo', axis = 1, inplace = True)\n",
    "df_training.drop('ano', axis = 1, inplace = True)\n",
    "df_training.drop('pessoas', axis = 1, inplace = True)\n",
    "df_training.drop('mortos', axis = 1, inplace = True)\n",
    "df_training.drop('feridos_leves', axis = 1, inplace = True)\n",
    "df_training.drop('ilesos', axis = 1, inplace = True)\n",
    "df_training.drop('ignorados', axis = 1, inplace = True)\n",
    "df_training.drop('feridos', axis = 1, inplace = True)\n",
    "df_training.drop('veiculos', axis = 1, inplace = True)\n",
    "df_training.drop('latitude', axis = 1, inplace = True)\n",
    "df_training.drop('longitude', axis = 1, inplace = True)\n",
    "df_training.drop('regional', axis = 1, inplace = True)\n",
    "df_training.drop('delegacia', axis = 1, inplace = True)\n",
    "df_training.drop('uop', axis = 1, inplace = True)\n",
    "\n",
    "\n",
    "# Specific drops for 2017\n",
    "df_training.drop('pesid', axis = 1, inplace = True)\n",
    "df_training.drop('id_veiculo', axis = 1, inplace = True)\n",
    "df_training.drop('tipo_veiculo', axis = 1, inplace = True)\n",
    "df_training.drop('marca', axis = 1, inplace = True)\n",
    "df_training.drop('ano_fabricacao_veiculo', axis = 1, inplace = True)\n",
    "df_training.drop('tipo_envolvido', axis = 1, inplace = True)\n",
    "df_training.drop('estado_fisico', axis = 1, inplace = True)\n",
    "df_training.drop('idade', axis = 1, inplace = True)\n",
    "df_training.drop('sexo', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886eda59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing inconsistent values with null values\n",
    "df_training.replace({'(null)': np.nan, '': np.nan, \n",
    "                     'Null': np.nan, 'NuLL': np.nan, \n",
    "                     'NULL': np.nan, 'null': np.nan, \n",
    "                     'Outras': np.nan, 'NaN': np.nan, \n",
    "                     'nan': np.nan, 'Ignorado': np.nan, \n",
    "                     'Ignorada': np.nan, 'Não Informado': np.nan, \n",
    "                     'Não Informada': np.nan, 'Outros': np.nan, \n",
    "                     'NAN': np.nan, 'NA': np.nan, 'xx': np.nan}, inplace = True)\n",
    "\n",
    "# Dropping all instances with null values from the df_training\n",
    "df_training = df_training.dropna(how = 'any', axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ac789f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing inconsistent values with null values\n",
    "df_test.replace({'(null)': np.nan, '': np.nan, \n",
    "                 'Null': np.nan, 'NuLL': np.nan, \n",
    "                 'NULL': np.nan, 'null': np.nan, \n",
    "                 'Outras': np.nan, 'NaN': np.nan, \n",
    "                 'nan': np.nan, 'Ignorado': np.nan, \n",
    "                 'Ignorada': np.nan, 'Não Informado': np.nan, \n",
    "                 'Não Informada': np.nan, 'Outros': np.nan, \n",
    "                 'NAN': np.nan, 'NA': np.nan, 'xx': np.nan}, inplace = True)\n",
    "\n",
    "# Dropping all instances with null values from the df_test\n",
    "df_test = df_test.dropna(how = 'any', axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c3344c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusting values with the same meaning but different values\n",
    "\n",
    "# Training\n",
    "\n",
    "# Time of day\n",
    "df_training.loc[df_training['fase_dia'] == 'Plena noite', 'fase_dia'] = 'Plena Noite'\n",
    "\n",
    "# Weather condition\n",
    "df_training.loc[df_training['condicao_metereologica'] == 'Ceu Claro', 'condicao_metereologica'] = 'Céu Claro'\n",
    "df_training.loc[df_training['condicao_metereologica'] == 'Nevoeiro/neblina', 'condicao_metereologica'] = 'Nevoeiro/Neblina'\n",
    "\n",
    "# Day of the week\n",
    "df_training.loc[df_training['dia_semana'] == 'Segunda', 'dia_semana'] = 'segunda-feira'\n",
    "df_training.loc[df_training['dia_semana'] == 'Terça', 'dia_semana'] = 'terça-feira'\n",
    "df_training.loc[df_training['dia_semana'] == 'Quarta', 'dia_semana'] = 'quarta-feira'\n",
    "df_training.loc[df_training['dia_semana'] == 'Quinta', 'dia_semana'] = 'quinta-feira'\n",
    "\n",
    "df_training.loc[df_training['dia_semana'] == 'Sexta', 'dia_semana'] = 'sexta-feira'\n",
    "df_training.loc[df_training['dia_semana'] == 'Sábado', 'dia_semana'] = 'sábado'\n",
    "df_training.loc[df_training['dia_semana'] == 'Domingo', 'dia_semana'] = 'domingo'\n",
    "\n",
    "# Type of accident\n",
    "df_training.loc[df_training['tipo_acidente'] == 'Atropelamento de Animal', 'tipo_acidente'] = 'Atropelamento de animal'\n",
    "df_training.loc[df_training['tipo_acidente'] == 'Atropelamento de pessoa', 'tipo_acidente'] = 'Atropelamento de Pedestre'\n",
    "df_training.loc[df_training['tipo_acidente'] == 'Colisão com objeto móvel', 'tipo_acidente'] = 'Colisão com objeto em movimento'\n",
    "\n",
    "df_training.loc[df_training['tipo_acidente'] == 'Colisão com objeto estático', 'tipo_acidente'] = 'Colisão com objeto fixo'\n",
    "df_training.loc[df_training['tipo_acidente'] == 'Colisão transversal', 'tipo_acidente'] = 'Colisão Transversal'\n",
    "df_training.loc[df_training['tipo_acidente'] == 'Danos eventuais', 'tipo_acidente'] = 'Danos Eventuais'\n",
    "\n",
    "df_training.loc[df_training['tipo_acidente'] == 'Derramamento de Carga', 'tipo_acidente'] = 'Derramamento de carga'\n",
    "df_training.loc[df_training['tipo_acidente'] == 'Eventos Atípicos', 'tipo_acidente'] = 'Eventos atípicos'\n",
    "df_training.loc[df_training['tipo_acidente'] == 'Saída de leito carroçável', 'tipo_acidente'] = 'Saída de Pista'\n",
    "\n",
    "# Cause of the accident\n",
    "df_training.loc[df_training['causa_acidente'] == 'Ingestão de Álcool', 'causa_acidente'] = 'Ingestão de álcool'\n",
    "df_training.loc[df_training['causa_acidente'] == 'Ingestão de álcool ou de substâncias psicoativas pelo pedestre', 'causa_acidente'] = 'Ingestão de álcool e/ou substâncias psicoativas pelo pedestre'\n",
    "df_training.loc[df_training['causa_acidente'] == 'Ultrapassagem Indevida', 'causa_acidente'] = 'Ultrapassagem indevida'\n",
    "\n",
    "df_training.loc[df_training['causa_acidente'] == 'Defeito mecânico em veículo', 'causa_acidente'] = 'Defeito Mecânico no Veículo'\n",
    "df_training.loc[df_training['causa_acidente'] == 'Velocidade Incompatível', 'causa_acidente'] = 'Velocidade incompatível'\n",
    "df_training.loc[df_training['causa_acidente'] == 'Dormindo', 'causa_acidente'] = 'Condutor Dormindo'\n",
    "\n",
    "df_training.loc[df_training['causa_acidente'] == 'Fenômenos da Natureza', 'causa_acidente'] = 'Fenômenos da natureza'\n",
    "df_training.loc[df_training['causa_acidente'] == 'Restrição de Visibilidade', 'causa_acidente'] = 'Restrição de visibilidade'\n",
    "df_training.loc[df_training['causa_acidente'] == 'Ausência de reação do condutor', 'causa_acidente'] = 'Reação tardia ou ineficiente do condutor'\n",
    "\n",
    "df_training.loc[df_training['causa_acidente'] == 'Deficiência do Sistema de Iluminação/Sinalização', 'causa_acidente'] = 'Deficiência na sinalização/iluminação do veículo'\n",
    "df_training.loc[df_training['causa_acidente'] == 'Pedestre andava na pista', 'causa_acidente'] = 'Pedestre na pista'\n",
    "\n",
    "# Accident classification\n",
    "df_training.loc[(df_training['classificacao_acidente'] == 'Com Vítimas Feridas') & (df_training['feridos_graves'] == 0), 'classificacao_acidente'] = 'Não Grave'\n",
    "df_training.loc[(df_training['classificacao_acidente'] == 'Com Vítimas Feridas') & (df_training['feridos_graves'] >= 1), 'classificacao_acidente'] = 'Grave'\n",
    "\n",
    "df_training.loc[df_training['classificacao_acidente'] == 'Sem Vítimas', 'classificacao_acidente'] = 'Não Grave'\n",
    "df_training.loc[df_training['classificacao_acidente'] == 'Com Vítimas Fatais', 'classificacao_acidente'] = 'Grave'\n",
    "\n",
    "df_training.loc[(df_training['classificacao_acidente'] == 'Ignorado') & (df_training['feridos_graves'] == 0), 'classificacao_acidente'] = 'Não Grave'\n",
    "df_training.loc[(df_training['classificacao_acidente'] == 'Ignorado') & (df_training['feridos_graves'] >= 1), 'classificacao_acidente'] = 'Grave'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c09f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusting values with the same meaning but different values\n",
    "\n",
    "# Test\n",
    "\n",
    "# Time of day\n",
    "df_test.loc[df_test['fase_dia'] == 'Plena noite', 'fase_dia'] = 'Plena Noite'\n",
    "\n",
    "# Weather condition\n",
    "df_test.loc[df_test['condicao_metereologica'] == 'Ceu Claro', 'condicao_metereologica'] = 'Céu Claro'\n",
    "df_test.loc[df_test['condicao_metereologica'] == 'Nevoeiro/neblina', 'condicao_metereologica'] = 'Nevoeiro/Neblina'\n",
    "\n",
    "# Day of the week\n",
    "df_test.loc[df_test['dia_semana'] == 'Segunda', 'dia_semana'] = 'segunda-feira'\n",
    "df_test.loc[df_test['dia_semana'] == 'Terça', 'dia_semana'] = 'terça-feira'\n",
    "df_test.loc[df_test['dia_semana'] == 'Quarta', 'dia_semana'] = 'quarta-feira'\n",
    "df_test.loc[df_test['dia_semana'] == 'Quinta', 'dia_semana'] = 'quinta-feira'\n",
    "\n",
    "df_test.loc[df_test['dia_semana'] == 'Sexta', 'dia_semana'] = 'sexta-feira'\n",
    "df_test.loc[df_test['dia_semana'] == 'Sábado', 'dia_semana'] = 'sábado'\n",
    "df_test.loc[df_test['dia_semana'] == 'Domingo', 'dia_semana'] = 'domingo'\n",
    "\n",
    "# Type of accident\n",
    "df_test.loc[df_test['tipo_acidente'] == 'Atropelamento de Animal', 'tipo_acidente'] = 'Atropelamento de animal'\n",
    "df_test.loc[df_test['tipo_acidente'] == 'Atropelamento de pessoa', 'tipo_acidente'] = 'Atropelamento de Pedestre'\n",
    "df_test.loc[df_test['tipo_acidente'] == 'Colisão com objeto móvel', 'tipo_acidente'] = 'Colisão com objeto em movimento'\n",
    "\n",
    "df_test.loc[df_test['tipo_acidente'] == 'Colisão com objeto estático', 'tipo_acidente'] = 'Colisão com objeto fixo'\n",
    "df_test.loc[df_test['tipo_acidente'] == 'Colisão transversal', 'tipo_acidente'] = 'Colisão Transversal'\n",
    "df_test.loc[df_test['tipo_acidente'] == 'Danos eventuais', 'tipo_acidente'] = 'Danos Eventuais'\n",
    "\n",
    "df_test.loc[df_test['tipo_acidente'] == 'Derramamento de Carga', 'tipo_acidente'] = 'Derramamento de carga'\n",
    "df_test.loc[df_test['tipo_acidente'] == 'Eventos Atípicos', 'tipo_acidente'] = 'Eventos atípicos'\n",
    "df_test.loc[df_test['tipo_acidente'] == 'Saída de leito carroçável', 'tipo_acidente'] = 'Saída de Pista'\n",
    "\n",
    "# Cause of the accident\n",
    "df_test.loc[df_test['causa_acidente'] == 'Ingestão de Álcool', 'causa_acidente'] = 'Ingestão de álcool'\n",
    "df_test.loc[df_test['causa_acidente'] == 'Ingestão de álcool ou de substâncias psicoativas pelo pedestre', 'causa_acidente'] = 'Ingestão de álcool e/ou substâncias psicoativas pelo pedestre'\n",
    "df_test.loc[df_test['causa_acidente'] == 'Ultrapassagem Indevida', 'causa_acidente'] = 'Ultrapassagem indevida'\n",
    "\n",
    "df_test.loc[df_test['causa_acidente'] == 'Defeito mecânico em veículo', 'causa_acidente'] = 'Defeito Mecânico no Veículo'\n",
    "df_test.loc[df_test['causa_acidente'] == 'Velocidade Incompatível', 'causa_acidente'] = 'Velocidade incompatível'\n",
    "df_test.loc[df_test['causa_acidente'] == 'Dormindo', 'causa_acidente'] = 'Condutor Dormindo'\n",
    "\n",
    "df_test.loc[df_test['causa_acidente'] == 'Fenômenos da Natureza', 'causa_acidente'] = 'Fenômenos da natureza'\n",
    "df_test.loc[df_test['causa_acidente'] == 'Restrição de Visibilidade', 'causa_acidente'] = 'Restrição de visibilidade'\n",
    "df_test.loc[df_test['causa_acidente'] == 'Ausência de reação do condutor', 'causa_acidente'] = 'Reação tardia ou ineficiente do condutor'\n",
    "\n",
    "df_test.loc[df_test['causa_acidente'] == 'Deficiência do Sistema de Iluminação/Sinalização', 'causa_acidente'] = 'Deficiência na sinalização/iluminação do veículo'\n",
    "df_test.loc[df_test['causa_acidente'] == 'Pedestre andava na pista', 'causa_acidente'] = 'Pedestre na pista'\n",
    "\n",
    "# Accident classification\n",
    "df_test.loc[(df_test['classificacao_acidente'] == 'Com Vítimas Feridas') & (df_test['feridos_graves'] == 0), 'classificacao_acidente'] = 'Não Grave'\n",
    "df_test.loc[(df_test['classificacao_acidente'] == 'Com Vítimas Feridas') & (df_test['feridos_graves'] >= 1), 'classificacao_acidente'] = 'Grave'\n",
    "\n",
    "df_test.loc[df_test['classificacao_acidente'] == 'Sem Vítimas', 'classificacao_acidente'] = 'Não Grave'\n",
    "df_test.loc[df_test['classificacao_acidente'] == 'Com Vítimas Fatais', 'classificacao_acidente'] = 'Grave'\n",
    "\n",
    "df_test.loc[(df_test['classificacao_acidente'] == 'Ignorado') & (df_test['feridos_graves'] == 0), 'classificacao_acidente'] = 'Não Grave'\n",
    "df_test.loc[(df_test['classificacao_acidente'] == 'Ignorado') & (df_test['feridos_graves'] >= 1), 'classificacao_acidente'] = 'Grave'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7af64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping duplicate rows from the training dataset\n",
    "df_training = df_training.drop_duplicates(ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c589c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the data to a file in CSV format\n",
    "df_training.to_csv('../data/trusted/trusted_file_training.csv', index = False)\n",
    "\n",
    "df_test.to_csv('../data/trusted/trusted_file_test.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66602a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
