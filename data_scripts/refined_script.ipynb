{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a348f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "onehotencoder = OneHotEncoder()\n",
    "\n",
    "# Importing the training dataset\n",
    "df_training = pd.read_csv('../data/trusted/trusted_file_training.csv')\n",
    "\n",
    "# Importing the test dataset\n",
    "df_test = pd.read_csv('../data/trusted/trusted_file_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca935896",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c9e91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f522327b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the variables to be used in training the models\n",
    "# Training\n",
    "\n",
    "# UF\n",
    "uf = df_training['uf']\n",
    "ufDF = pd.DataFrame(uf)\n",
    "\n",
    "# Time of day\n",
    "fd = df_training['fase_dia']\n",
    "fdDF = pd.DataFrame(fd)\n",
    "\n",
    "# Weather condition\n",
    "cm = df_training['condicao_metereologica']\n",
    "cmDF = pd.DataFrame(cm)\n",
    "\n",
    "# Type of accident\n",
    "ta = df_training['tipo_acidente']\n",
    "taDF = pd.DataFrame(ta)\n",
    "\n",
    "# Cause of the accident\n",
    "ca = df_training['causa_acidente']\n",
    "caDF = pd.DataFrame(ca)\n",
    "\n",
    "# Day of the week\n",
    "ds = df_training['dia_semana']\n",
    "dsDF = pd.DataFrame(ds)\n",
    "\n",
    "# Direction of the road\n",
    "sv = df_training['sentido_via']\n",
    "svDF = pd.DataFrame(sv)\n",
    "\n",
    "# Type of road\n",
    "tp = df_training['tipo_pista']\n",
    "tpDF = pd.DataFrame(tp)\n",
    "\n",
    "# Road layout\n",
    "tv = df_training['tracado_via']\n",
    "tvDF = pd.DataFrame(tv)\n",
    "\n",
    "# Accident classification\n",
    "cla_acid = df_training['classificacao_acidente']\n",
    "cla_acidDF = pd.DataFrame(cla_acid)\n",
    "\n",
    "# Concatenating the training datasets\n",
    "df_training = pd.concat([fdDF, cmDF, taDF, caDF, dsDF, svDF, tpDF, tvDF, cla_acidDF, ufDF], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e294428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the same variables used in training for the test dataset\n",
    "# Test\n",
    "\n",
    "# UF\n",
    "uf = df_test['uf']\n",
    "ufDF = pd.DataFrame(uf)\n",
    "\n",
    "# Time of day\n",
    "fd = df_test['fase_dia']\n",
    "fdDF = pd.DataFrame(fd)\n",
    "\n",
    "# Weather condition\n",
    "cm = df_test['condicao_metereologica']\n",
    "cmDF = pd.DataFrame(cm)\n",
    "\n",
    "# Type of accident\n",
    "ta = df_test['tipo_acidente']\n",
    "taDF = pd.DataFrame(ta)\n",
    "\n",
    "# Cause of the accident\n",
    "ca = df_test['causa_acidente']\n",
    "caDF = pd.DataFrame(ca)\n",
    "\n",
    "# Day of the week\n",
    "ds = df_test['dia_semana']\n",
    "dsDF = pd.DataFrame(ds)\n",
    "\n",
    "# Direction of the road\n",
    "sv = df_test['sentido_via']\n",
    "svDF = pd.DataFrame(sv)\n",
    "\n",
    "# Type of road\n",
    "tp = df_test['tipo_pista']\n",
    "tpDF = pd.DataFrame(tp)\n",
    "\n",
    "# Road layout\n",
    "tv = df_test['tracado_via']\n",
    "tvDF = pd.DataFrame(tv)\n",
    "\n",
    "# Accident classification\n",
    "cla_acid = df_test['classificacao_acidente']\n",
    "cla_acidDF = pd.DataFrame(cla_acid)\n",
    "\n",
    "# Concatenating the test datasets\n",
    "df_test = pd.concat([fdDF, cmDF, taDF, caDF, dsDF, svDF, tpDF, tvDF, cla_acidDF, ufDF], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6031b687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "# Adding the string \"xx\" to all instances where \"uf\" is different from the ones mentioned below\n",
    "df_training.loc[(df_training['uf'] != 'AC') & \n",
    "                (df_training['uf'] != 'AP') & \n",
    "                (df_training['uf'] != 'AM') & \n",
    "                (df_training['uf'] != 'PA') & \n",
    "                (df_training['uf'] != 'RO') & \n",
    "                (df_training['uf'] != 'RR') & \n",
    "                (df_training['uf'] != 'TO') & \n",
    "                (df_training['uf'] != 'MA') & \n",
    "                (df_training['uf'] != 'MT'), 'uf'] = 'xx'\n",
    "\n",
    "# Transforming \"xx\" into null values\n",
    "df_training.replace({'xx': np.nan}, inplace = True)\n",
    "\n",
    "# Test\n",
    "# Adding the string \"xx\" to all instances where \"uf\" is different from the ones mentioned below\n",
    "df_test.loc[(df_test['uf'] != 'AC') & \n",
    "            (df_test['uf'] != 'AP') & \n",
    "            (df_test['uf'] != 'AM') & \n",
    "            (df_test['uf'] != 'PA') & \n",
    "            (df_test['uf'] != 'RO') & \n",
    "            (df_test['uf'] != 'RR') & \n",
    "            (df_test['uf'] != 'TO') & \n",
    "            (df_test['uf'] != 'MA') & \n",
    "            (df_test['uf'] != 'MT'), 'uf'] = 'xx'\n",
    "\n",
    "# Transforming \"xx\" into null values\n",
    "df_test.replace({'xx': np.nan}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4759d9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "# Dropping all instances with null values from the df_training\n",
    "df_training = df_training.dropna(how = 'any', axis = 0)\n",
    "\n",
    "# Resetting the index numbering\n",
    "df_training.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# Test\n",
    "# Dropping all instances with null values from the df_test\n",
    "df_test = df_test.dropna(how = 'any', axis = 0)\n",
    "\n",
    "# Resetting the index numbering\n",
    "df_test.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18be37ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the \"uf\" column from the training and test datasets\n",
    "df_training.drop('uf', axis = 1, inplace = True)\n",
    "df_test.drop('uf', axis = 1, inplace = True)\n",
    "\n",
    "# Dropping duplicate rows from the training dataset\n",
    "df_training = df_training.drop_duplicates(ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8acf5c5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "# Creating a column to represent the original order of the rows\n",
    "df_training['original_order'] = range(len(df_training))\n",
    "\n",
    "# Rows containing the variable \"Não Grave\"\n",
    "cla_acid_nao_grave_indexs = df_training[df_training['classificacao_acidente'] == 'Não Grave'].index\n",
    "\n",
    "# Randomly selecting the rows to be excluded (95% of \"Não Grave\" accidents)\n",
    "drop_indexs = np.random.choice(cla_acid_nao_grave_indexs, size = int(len(cla_acid_nao_grave_indexs) * 0.95), replace = False)\n",
    "\n",
    "# Deleting the rows from the df_training\n",
    "df_training = df_training.drop(drop_indexs)\n",
    "\n",
    "# Reordering the dataframe based on the \"ordem_original\" column\n",
    "df_training = df_training.sort_values('original_order').reset_index(drop = True)\n",
    "\n",
    "# Dropping \"original_order\"\n",
    "df_training.drop('original_order', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a61c0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "\n",
    "# As they are isolated databases, the training and test DataFrames have different dimensions\n",
    "# As the dimension of the test inputs has to be the same as the training inputs, some less...\n",
    "# frequent features are discarded to ensure the quantity of inputs in both databases is the same\n",
    "\n",
    "# Dropping some features from the df_test of 2021 so that the number of features in both dataframes is equivalent\n",
    "while df_training.nunique().sum() != df_test.nunique().sum():\n",
    "    \n",
    "    # Gets the index of the last row of the dataframe\n",
    "    indexs = df_test['causa_acidente'].value_counts().tail(1).index\n",
    "\n",
    "    # Deletes the rows with the obtained indexs\n",
    "    df_test.drop(df_test[df_test['causa_acidente'].isin(indexs)].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48dd0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "# Replacing the observations of \"classificacao_acidente\" with 0 or 1\n",
    "df_training['classificacao_acidente'].replace('Não Grave', int(0), inplace = True)\n",
    "\n",
    "df_training['classificacao_acidente'].replace('Grave', int(1), inplace = True)\n",
    "\n",
    "# Test\n",
    "# Replacing the observations of \"classificacao_acidente\" with 0 or 1\n",
    "df_test['classificacao_acidente'].replace('Não Grave', int(0), inplace = True)\n",
    "\n",
    "df_test['classificacao_acidente'].replace('Grave', int(1), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012f5ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming the data, concatenating the corresponding columns, and storing it in a dataframe\n",
    "# Training\n",
    "# INPUTS\n",
    "\n",
    "# Time of day\n",
    "fd = ['fase_dia']\n",
    "\n",
    "onehotencoder.fit_transform(df_training[fd])\n",
    "columns_fd = [fd[0] + ' - ' + cat_name for cat_name in onehotencoder.categories_][0]\n",
    "fdDF = pd.DataFrame(onehotencoder.fit_transform(df_training[fd]).toarray(), columns = columns_fd)\n",
    "\n",
    "# Weather condition\n",
    "cm = ['condicao_metereologica']\n",
    "\n",
    "onehotencoder.fit_transform(df_training[cm])\n",
    "columns_cm = [cm[0] + ' - ' + cat_name for cat_name in onehotencoder.categories_][0]\n",
    "cmDF = pd.DataFrame(onehotencoder.fit_transform(df_training[cm]).toarray(), columns = columns_cm)\n",
    "\n",
    "# Type of accident\n",
    "ta = ['tipo_acidente']\n",
    "\n",
    "onehotencoder.fit_transform(df_training[ta])\n",
    "columns_ta = [ta[0] + ' - ' + cat_name for cat_name in onehotencoder.categories_][0]\n",
    "taDF = pd.DataFrame(onehotencoder.fit_transform(df_training[ta]).toarray(), columns = columns_ta)\n",
    "\n",
    "# Cause of the accident\n",
    "ca = ['causa_acidente']\n",
    "\n",
    "onehotencoder.fit_transform(df_training[ca])\n",
    "columns_ca = [ca[0] + ' - ' + cat_name for cat_name in onehotencoder.categories_][0]\n",
    "caDF = pd.DataFrame(onehotencoder.fit_transform(df_training[ca]).toarray(), columns = columns_ca)\n",
    "\n",
    "# Day of the week\n",
    "ds = ['dia_semana']\n",
    "\n",
    "onehotencoder.fit_transform(df_training[ds])\n",
    "columns_ds = [ds[0] + ' - ' + cat_name for cat_name in onehotencoder.categories_][0]\n",
    "dsDF = pd.DataFrame(onehotencoder.fit_transform(df_training[ds]).toarray(), columns = columns_ds)\n",
    "\n",
    "# Direction of the road\n",
    "sv = ['sentido_via']\n",
    "\n",
    "onehotencoder.fit_transform(df_training[sv])\n",
    "columns_sv = [sv[0] + ' - ' + cat_name for cat_name in onehotencoder.categories_][0]\n",
    "svDF = pd.DataFrame(onehotencoder.fit_transform(df_training[sv]).toarray(), columns = columns_sv)\n",
    "\n",
    "# Type of road\n",
    "tp = ['tipo_pista']\n",
    "\n",
    "onehotencoder.fit_transform(df_training[tp])\n",
    "columns_tp = [tp[0] + ' - ' + cat_name for cat_name in onehotencoder.categories_][0]\n",
    "tpDF = pd.DataFrame(onehotencoder.fit_transform(df_training[tp]).toarray(), columns = columns_tp)\n",
    "\n",
    "# Road layout\n",
    "tv = ['tracado_via']\n",
    "\n",
    "onehotencoder.fit_transform(df_training[tv])\n",
    "columns_tv = [tv[0] + ' - ' + cat_name for cat_name in onehotencoder.categories_][0]\n",
    "tvDF = pd.DataFrame(onehotencoder.fit_transform(df_training[tv]).toarray(), columns = columns_tv)\n",
    "\n",
    "inputs_training_df = pd.concat([fdDF, cmDF, taDF, caDF, dsDF, svDF, tpDF, tvDF], axis = 1)\n",
    "\n",
    "# OUTPUTS\n",
    "\n",
    "# Accident classification\n",
    "cla_acid = ['classificacao_acidente']\n",
    "\n",
    "outputs_training_df = pd.DataFrame(df_training[cla_acid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4fe33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming the data, concatenating the corresponding columns, and storing it in a dataframe\n",
    "# Test\n",
    "# INPUTS\n",
    "\n",
    "# Time of day\n",
    "fd = ['fase_dia']\n",
    "\n",
    "onehotencoder.fit_transform(df_test[fd])\n",
    "columns_fd = [fd[0] + ' - ' + cat_name for cat_name in onehotencoder.categories_][0]\n",
    "fdDF_test = pd.DataFrame(onehotencoder.fit_transform(df_test[fd]).toarray(), columns = columns_fd)\n",
    "\n",
    "# Weather condition\n",
    "cm = ['condicao_metereologica']\n",
    "\n",
    "onehotencoder.fit_transform(df_test[cm])\n",
    "columns_cm = [cm[0] + ' - ' + cat_name for cat_name in onehotencoder.categories_][0]\n",
    "cmDF_test = pd.DataFrame(onehotencoder.fit_transform(df_test[cm]).toarray(), columns = columns_cm)\n",
    "\n",
    "# Type of accident\n",
    "ta = ['tipo_acidente']\n",
    "\n",
    "onehotencoder.fit_transform(df_test[ta])\n",
    "columns_ta = [ta[0] + ' - ' + cat_name for cat_name in onehotencoder.categories_][0]\n",
    "taDF_test = pd.DataFrame(onehotencoder.fit_transform(df_test[ta]).toarray(), columns = columns_ta)\n",
    "\n",
    "# Cause of the accident\n",
    "ca = ['causa_acidente']\n",
    "\n",
    "onehotencoder.fit_transform(df_test[ca])\n",
    "columns_ca = [ca[0] + ' - ' + cat_name for cat_name in onehotencoder.categories_][0]\n",
    "caDF_test = pd.DataFrame(onehotencoder.fit_transform(df_test[ca]).toarray(), columns = columns_ca)\n",
    "\n",
    "# Day of the week\n",
    "ds = ['dia_semana']\n",
    "\n",
    "onehotencoder.fit_transform(df_test[ds])\n",
    "columns_ds = [ds[0] + ' - ' + cat_name for cat_name in onehotencoder.categories_][0]\n",
    "dsDF_test = pd.DataFrame(onehotencoder.fit_transform(df_test[ds]).toarray(), columns = columns_ds)\n",
    "\n",
    "# Direction of the road\n",
    "sv = ['sentido_via']\n",
    "\n",
    "onehotencoder.fit_transform(df_test[sv])\n",
    "columns_sv = [sv[0] + ' - ' + cat_name for cat_name in onehotencoder.categories_][0]\n",
    "svDF_test = pd.DataFrame(onehotencoder.fit_transform(df_test[sv]).toarray(), columns = columns_sv)\n",
    "\n",
    "# Type of road\n",
    "tp = ['tipo_pista']\n",
    "\n",
    "onehotencoder.fit_transform(df_test[tp])\n",
    "columns_tp = [tp[0] + ' - ' + cat_name for cat_name in onehotencoder.categories_][0]\n",
    "tpDF_test = pd.DataFrame(onehotencoder.fit_transform(df_test[tp]).toarray(), columns = columns_tp)\n",
    "\n",
    "# Road layout\n",
    "tv = ['tracado_via']\n",
    "\n",
    "onehotencoder.fit_transform(df_test[tv])\n",
    "columns_tv = [tv[0] + ' - ' + cat_name for cat_name in onehotencoder.categories_][0]\n",
    "tvDF_test = pd.DataFrame(onehotencoder.fit_transform(df_test[tv]).toarray(), columns = columns_tv)\n",
    "\n",
    "inputs_test_df = pd.concat([fdDF_test, cmDF_test, taDF_test, caDF_test, dsDF_test, svDF_test, tpDF_test, tvDF_test], axis = 1)\n",
    "\n",
    "# OUTPUTS\n",
    "\n",
    "# Accident classification\n",
    "cla_acid = ['classificacao_acidente']\n",
    "\n",
    "outputs_test_df = pd.DataFrame(df_test[cla_acid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2302766e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the data to a file in CSV format\n",
    "inputs_training_df.to_csv('../data/refined/inputs_training_df.csv', index = False)\n",
    "outputs_training_df.to_csv('../data/refined/outputs_training_df.csv', index = False)\n",
    "\n",
    "inputs_test_df.to_csv('../data/refined/inputs_test_df.csv', index = False)\n",
    "outputs_test_df.to_csv('../data/refined/outputs_test_df.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfcbca1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
